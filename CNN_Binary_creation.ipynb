{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ebmAvysVeA"
      },
      "source": [
        "# Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPJiBA0FaWlB",
        "outputId": "702f5593-ca2c-4721-c913-f368a8880e8a"
      },
      "outputs": [],
      "source": [
        "# Importar librerías necesarias\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Establecer la semilla para reproducibilidad\n",
        "random.seed(42)\n",
        "\n",
        "# Definir la carpeta para guardar los CSV\n",
        "csv_dir = \"./results/csv_files\"\n",
        "os.makedirs(csv_dir, exist_ok=True)  # Crea la carpeta si no existe\n",
        "\n",
        "# Directorio raíz de las imágenes reales\n",
        "# (Carpeta que contiene subcarpetas \"Bacterial\", \"COVID-19\" y \"Normal\")\n",
        "real_data_dir = \"./data/covid-chest-xray\"\n",
        "\n",
        "# Directorio de las imágenes aumentadas\n",
        "# (Carpeta que contiene subcarpetas \"Bacterial\", \"COVID-19\" y \"Normal\")\n",
        "augmented_data_dir = \"./data/data_augmentation\"\n",
        "\n",
        "# Lista de clases según la estructura de tus carpetas\n",
        "clases = [\"Bacterial\", \"COVID-19\", \"Normal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bacterial: 47 imágenes reales\n",
            "COVID-19: 341 imágenes reales\n",
            "Normal: 486 imágenes reales\n"
          ]
        }
      ],
      "source": [
        "def obtener_rutas_imagenes(ruta_base, extension=(\"jpg\", \"jpeg\", \"png\", \"tiff\")):\n",
        "    rutas = []\n",
        "    for ext in extension:\n",
        "        rutas.extend(glob.glob(os.path.join(ruta_base, f\"*.{ext}\")))\n",
        "    return rutas\n",
        "\n",
        "\n",
        "# Crear un diccionario con las rutas de imágenes reales para cada clase\n",
        "imagenes_reales = {}\n",
        "for clase in clases:\n",
        "    ruta_clase = os.path.join(real_data_dir, clase)\n",
        "    imagenes_reales[clase] = obtener_rutas_imagenes(ruta_clase)\n",
        "    print(f\"{clase}: {len(imagenes_reales[clase])} imágenes reales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COVID-19 - Total: 341, Train: 238, Val: 51, Test: 52\n",
            "No-COVID-19 - Total: 533, Train: 373, Val: 79, Test: 81\n"
          ]
        }
      ],
      "source": [
        "# Definir porcentajes\n",
        "porc_train = 0.70\n",
        "porc_val = 0.15\n",
        "porc_test = 0.15\n",
        "\n",
        "# Diccionarios para almacenar las rutas de cada conjunto\n",
        "train_real = {}\n",
        "val_real = {}\n",
        "test_real = {}\n",
        "\n",
        "categories = ['COVID-19', 'No-COVID-19']\n",
        "\n",
        "for category in categories:\n",
        "    if category == 'COVID-19':\n",
        "        imagenes = imagenes_reales[category].copy()\n",
        "    else:\n",
        "        imagenes = imagenes_reales['Bacterial'].copy() + imagenes_reales['Normal'].copy()\n",
        "    random.shuffle(imagenes)\n",
        "\n",
        "    total = len(imagenes)\n",
        "    n_train = int(total * porc_train)\n",
        "    n_val = int(total * porc_val)\n",
        "    # El resto va a test, asegurando que se asignen todas las imágenes\n",
        "    n_test = total - n_train - n_val\n",
        "\n",
        "    train_real[category] = imagenes[:n_train]\n",
        "    val_real[category] = imagenes[n_train : n_train + n_val]\n",
        "    test_real[category] = imagenes[n_train + n_val :]\n",
        "\n",
        "    print(\n",
        "        f\"{category} - Total: {total}, Train: {len(train_real[category])}, Val: {len(val_real[category])}, Test: {len(test_real[category])}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Conjunto     Clase                                               Ruta\n",
            "0    train  COVID-19  ./data/covid-chest-xray/COVID-19/COVID-19-246.png\n",
            "1    train  COVID-19  ./data/covid-chest-xray/COVID-19/COVID-19-338.jpg\n",
            "2    train  COVID-19  ./data/covid-chest-xray/COVID-19/COVID-19-42.jpeg\n",
            "3    train  COVID-19   ./data/covid-chest-xray/COVID-19/COVID-19-99.png\n",
            "4    train  COVID-19  ./data/covid-chest-xray/COVID-19/COVID-19-263....\n",
            "Conjunto  Clase      \n",
            "test      COVID-19        52\n",
            "          No-COVID-19     81\n",
            "train     COVID-19       238\n",
            "          No-COVID-19    373\n",
            "val       COVID-19        51\n",
            "          No-COVID-19     79\n",
            "dtype: int64\n",
            "Registro de imágenes guardado en: ./results/csv_files/registro_imagenes_reales_binary_2.csv\n"
          ]
        }
      ],
      "source": [
        "def crear_registro(rutas_dict, conjunto_name):\n",
        "    registros = []\n",
        "    for clase, rutas in rutas_dict.items():\n",
        "        for ruta in rutas:\n",
        "            registros.append({\"Conjunto\": conjunto_name, \"Clase\": clase, \"Ruta\": ruta})\n",
        "    return pd.DataFrame(registros)\n",
        "\n",
        "\n",
        "df_train = crear_registro(train_real, \"train\")\n",
        "df_val = crear_registro(val_real, \"val\")\n",
        "df_test = crear_registro(test_real, \"test\")\n",
        "\n",
        "# Concatenar y mostrar el registro completo\n",
        "df_registro = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
        "print(df_registro.head())\n",
        "print(df_registro.groupby([\"Conjunto\", \"Clase\"]).size())\n",
        "\n",
        "# Guardar el registro de imágenes reales\n",
        "csv_registro_imagenes = os.path.join(csv_dir, \"registro_imagenes_reales_binary_2.csv\")\n",
        "df_registro.to_csv(csv_registro_imagenes, index=False)\n",
        "print(f\"Registro de imágenes guardado en: {csv_registro_imagenes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COVID-19: 500 imágenes aumentadas\n",
            "No-COVID-19: 500 imágenes aumentadas\n"
          ]
        }
      ],
      "source": [
        "def obtener_rutas_limitadas(ruta_base, cantidad, extension=(\"jpg\", \"jpeg\", \"png\", \"tiff\")):\n",
        "    imagenes = obtener_rutas_imagenes(ruta_base, extension)\n",
        "    return random.sample(imagenes, min(cantidad, len(imagenes)))\n",
        "\n",
        "# Diccionario para almacenar rutas de imágenes aumentadas por clase\n",
        "imagenes_aug = {}\n",
        "for category in categories:   \n",
        "    # Insertar imágenes adicionales según la clase\n",
        "    if category == \"COVID-19\":\n",
        "        imagenes_aug[category] = obtener_rutas_limitadas(\"./data/data_augmentation/COVID-19\", 500)\n",
        "    else:\n",
        "        imagenes_aug[category] = obtener_rutas_limitadas(\"./data/data_augmentation/Bacterial\", 250)\n",
        "        imagenes_aug[category] += obtener_rutas_limitadas(\"./data/data_augmentation/Normal\", 250)\n",
        "    \n",
        "    print(f\"{category}: {len(imagenes_aug[category])} imágenes aumentadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COVID-19 - Train final: 238 reales + 500 aumentadas = 738 imágenes\n",
            "No-COVID-19 - Train final: 373 reales + 500 aumentadas = 873 imágenes\n"
          ]
        }
      ],
      "source": [
        "# Diccionario para el conjunto de entrenamiento final (reales + aumentadas)\n",
        "train_final = {}\n",
        "for category in categories:\n",
        "    reales = train_real[category]\n",
        "    aumentadas = imagenes_aug.get(category, [])\n",
        "    train_final[category] = reales + aumentadas\n",
        "    print(f\"{category} - Train final: {len(reales)} reales + {len(aumentadas)} aumentadas = {len(train_final[category])} imágenes\")\n",
        "\n",
        "df_train_final = crear_registro(train_final, \"train_final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clase\n",
            "COVID-19       738\n",
            "No-COVID-19    873\n",
            "dtype: int64\n",
            "Registro del conjunto de entrenamiento final guardado en: ./results/csv_files/registro_train_final_binary_2.csv\n"
          ]
        }
      ],
      "source": [
        "# Mostrar resumen por clase\n",
        "print(df_train_final.groupby(\"Clase\").size())\n",
        "\n",
        "# Guardar el registro del conjunto de entrenamiento final (reales + aumentadas)\n",
        "csv_train_final = os.path.join(csv_dir, \"registro_train_final_binary_2.csv\")\n",
        "df_train_final.to_csv(csv_train_final, index=False)\n",
        "print(f\"Registro del conjunto de entrenamiento final guardado en: {csv_train_final}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "División de imágenes reales:\n",
            "         Conjunto  COVID-19  No-COVID-19\n",
            "0  Train (reales)       238          373\n",
            "1             Val        51           79\n",
            "2            Test        52           81\n",
            "\n",
            "Conjunto de entrenamiento final (reales):\n",
            "         Clase  Train_final\n",
            "0     COVID-19          238\n",
            "1  No-COVID-19          373\n"
          ]
        }
      ],
      "source": [
        "# Resumen de las cantidades en cada conjunto\n",
        "resumen = {\n",
        "    \"Conjunto\": [\"Train (reales)\", \"Val\", \"Test\"],\n",
        "    \"COVID-19\": [\n",
        "        len(train_real[\"COVID-19\"]),\n",
        "        len(val_real[\"COVID-19\"]),\n",
        "        len(test_real[\"COVID-19\"]),\n",
        "    ],\n",
        "    \"No-COVID-19\": [\n",
        "        len(train_real[\"No-COVID-19\"]),\n",
        "        len(val_real[\"No-COVID-19\"]),\n",
        "        len(test_real[\"No-COVID-19\"]),\n",
        "    ],\n",
        "}\n",
        "\n",
        "df_resumen = pd.DataFrame(resumen)\n",
        "print(\"División de imágenes reales:\")\n",
        "print(df_resumen)\n",
        "\n",
        "# Resumen de imágenes en el entrenamiento final (reales)\n",
        "resumen_train_final = {\n",
        "    \"Clase\": categories,\n",
        "    \"Train_final\": [len(train_final[category]) for category in categories],\n",
        "}\n",
        "\n",
        "df_resumen_train_final = pd.DataFrame(resumen_train_final)\n",
        "print(\"\\nConjunto de entrenamiento final (reales):\")\n",
        "print(df_resumen_train_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_train_final = os.path.join(csv_dir, \"registro_train_final_binary_2.csv\")\n",
        "df_train_final = pd.read_csv(csv_train_final)\n",
        "\n",
        "csv_registro_imagenes = os.path.join(csv_dir, \"registro_imagenes_reales_binary_2.csv\")\n",
        "df_registro = pd.read_csv(csv_registro_imagenes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1611 validated image filenames belonging to 2 classes.\n",
            "Clases encontradas: {'COVID-19': 0, 'No-COVID-19': 1}\n",
            "Found 133 validated image filenames belonging to 2 classes.\n",
            "Clases encontradas en test: {'COVID-19': 0, 'No-COVID-19': 1}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Crear generador para el conjunto de entrenamiento (solo rescaling)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Crear el generador de datos a partir del DataFrame de entrenamiento (imágenes reales + aumentadas)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=df_train_final,  # DataFrame con las imágenes de entrenamiento\n",
        "    x_col=\"Ruta\",  # Columna con las rutas de las imágenes\n",
        "    y_col=\"Clase\",  # Columna con las etiquetas de clase\n",
        "    target_size=(224, 224),  # Redimensionar las imágenes a 224x224\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",  # Para clasificación multiclase\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(\"Clases encontradas:\", train_generator.class_indices)\n",
        "\n",
        "# Crear generador para test (solo rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Filtrar el DataFrame para obtener solo las imágenes del conjunto \"test\"\n",
        "df_test = df_registro[df_registro[\"Conjunto\"] == \"test\"]\n",
        "\n",
        "# Crear el generador de datos para el conjunto de test\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=df_test,  # DataFrame con las imágenes reales de test\n",
        "    x_col=\"Ruta\",  # Columna que contiene las rutas de las imágenes\n",
        "    y_col=\"Clase\",  # Columna con las etiquetas de clase\n",
        "    target_size=(224, 224),  # Redimensiona las imágenes a 224x224\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",  # Para clasificación multiclase\n",
        "    shuffle=False,  # No se baraja para mantener el orden de test\n",
        ")\n",
        "\n",
        "print(\"Clases encontradas en test:\", test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc3EsCw8YUVZ",
        "outputId": "62fbb4bf-e399-42a1-db55-a5bfaeebc92b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-05 23:05:41.220743: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-05 23:05:41.500904: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-05 23:05:41.846679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741212342.137470     517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741212342.270578     517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-05 23:05:42.950009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Importar librerías necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    BatchNormalization,\n",
        "    Activation,\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IbHdRdMYWk9"
      },
      "source": [
        "# Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Definir la función que construye el modelo de CNN, con hiperparámetros ajustables.\n",
        "# =============================================================================\n",
        "def build_cnn(hp):\n",
        "    model = Sequential(\n",
        "        [\n",
        "            # Primera capa convolucional: se parametriza el número de filtros (entre 32 y 64, de 16 en 16)\n",
        "            Conv2D(\n",
        "                hp.Int(\"filters_1\", 32, 64, step=16),\n",
        "                (3, 3),\n",
        "                activation=None,\n",
        "                input_shape=(224, 224, 3),\n",
        "            ),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(hp.Float(\"dropout_1\", 0.2, 0.5, step=0.1)),\n",
        "            \n",
        "            # Segunda capa convolucional\n",
        "            Conv2D(hp.Int(\"filters_2\", 64, 128, step=32), (3, 3), activation=None),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(hp.Float(\"dropout_2\", 0.2, 0.5, step=0.1)),\n",
        "            \n",
        "            # Tercera capa convolucional\n",
        "            Conv2D(hp.Int(\"filters_3\", 128, 256, step=64), (3, 3), activation=None),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(hp.Float(\"dropout_3\", 0.3, 0.6, step=0.1)),\n",
        "            \n",
        "            # Capa de aplanamiento para pasar a las capas densas\n",
        "            Flatten(),\n",
        "            \n",
        "            # Capa densa con unidades parametrizables (entre 64 y 256, de 64 en 64)\n",
        "            Dense(hp.Int(\"dense_units\", 64, 256, step=64), activation=None),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            Dropout(hp.Float(\"dropout_dense\", 0.3, 0.6, step=0.1)),\n",
        "            \n",
        "            # Capa de salida: 2 neuronas para 2 clases, con activación softmax\n",
        "            Dense(2, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Definir el optimizador: Adam con tasa de aprendizaje seleccionada entre tres opciones.\n",
        "    optimizer = Adam(learning_rate=hp.Choice(\"learning_rate\", [1e-4, 5e-4, 1e-3]))\n",
        "\n",
        "    # Compilar el modelo usando entropía cruzada categórica (para clasificación multiclase)\n",
        "    # Se añaden varias métricas para evaluar: accuracy, precision, recall y AUC.\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=optimizer,\n",
        "        metrics=[\"accuracy\", \"precision\", \"recall\", \"AUC\"],\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yj45LgkYb72"
      },
      "source": [
        "# Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY3NrE6fYpyA"
      },
      "source": [
        "# Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from cnn_chest-xray_problem_binary_2/cnn_chest-xray_problem_binary_2/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Configurar el Random Search para buscar los mejores hiperparámetros\n",
        "# =============================================================================\n",
        "tuner = RandomSearch(\n",
        "    build_cnn,  # Función que construye el modelo\n",
        "    objective=\"val_accuracy\",  # Métrica a optimizar (precisión en validación)\n",
        "    max_trials=10,  # Número máximo de combinaciones a probar\n",
        "    executions_per_trial=1,  # Número de ejecuciones por cada combinación\n",
        "    directory=\"cnn_chest-xray_problem_binary\",  # Directorio para guardar resultados del tuner\n",
        "    project_name=\"cnn_chest-xray_problem_binary\",  # Nombre del proyecto\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# Definir Early Stopping para detener el entrenamiento si no mejora la precisión de validación\n",
        "# =============================================================================\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# Realizar la búsqueda de hiperparámetros usando los generadores de entrenamiento y validación.\n",
        "# Se asume que 'train_generator' y 'test_generator' están definidos previamente.\n",
        "# =============================================================================\n",
        "tuner.search(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,  # Aquí test_generator actúa como conjunto de validación\n",
        "    epochs=25,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in cnn_chest-xray_problem_binary_2/cnn_chest-xray_problem_binary_2\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "filters_1: 32\n",
            "dropout_1: 0.30000000000000004\n",
            "filters_2: 96\n",
            "dropout_2: 0.2\n",
            "filters_3: 128\n",
            "dropout_3: 0.3\n",
            "dense_units: 192\n",
            "dropout_dense: 0.3\n",
            "learning_rate: 0.001\n",
            "Score: 0.9924812316894531\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "filters_1: 32\n",
            "dropout_1: 0.30000000000000004\n",
            "filters_2: 96\n",
            "dropout_2: 0.4\n",
            "filters_3: 256\n",
            "dropout_3: 0.3\n",
            "dense_units: 64\n",
            "dropout_dense: 0.3\n",
            "learning_rate: 0.001\n",
            "Score: 0.969924807548523\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "filters_1: 64\n",
            "dropout_1: 0.4\n",
            "filters_2: 128\n",
            "dropout_2: 0.4\n",
            "filters_3: 256\n",
            "dropout_3: 0.5\n",
            "dense_units: 64\n",
            "dropout_dense: 0.3\n",
            "learning_rate: 0.001\n",
            "Score: 0.9624060392379761\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "filters_1: 64\n",
            "dropout_1: 0.2\n",
            "filters_2: 64\n",
            "dropout_2: 0.2\n",
            "filters_3: 128\n",
            "dropout_3: 0.3\n",
            "dense_units: 64\n",
            "dropout_dense: 0.5\n",
            "learning_rate: 0.0001\n",
            "Score: 0.3909774422645569\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "filters_1: 32\n",
            "dropout_1: 0.2\n",
            "filters_2: 128\n",
            "dropout_2: 0.30000000000000004\n",
            "filters_3: 128\n",
            "dropout_3: 0.4\n",
            "dense_units: 192\n",
            "dropout_dense: 0.5\n",
            "learning_rate: 0.0005\n",
            "Score: 0.3909774422645569\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "filters_1: 32\n",
            "dropout_1: 0.30000000000000004\n",
            "filters_2: 128\n",
            "dropout_2: 0.2\n",
            "filters_3: 192\n",
            "dropout_3: 0.5\n",
            "dense_units: 128\n",
            "dropout_dense: 0.3\n",
            "learning_rate: 0.0001\n",
            "Score: 0.3909774422645569\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "filters_1: 48\n",
            "dropout_1: 0.2\n",
            "filters_2: 96\n",
            "dropout_2: 0.4\n",
            "filters_3: 192\n",
            "dropout_3: 0.4\n",
            "dense_units: 64\n",
            "dropout_dense: 0.4\n",
            "learning_rate: 0.0001\n",
            "Score: 0.3909774422645569\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "filters_1: 32\n",
            "dropout_1: 0.2\n",
            "filters_2: 128\n",
            "dropout_2: 0.2\n",
            "filters_3: 128\n",
            "dropout_3: 0.4\n",
            "dense_units: 256\n",
            "dropout_dense: 0.3\n",
            "learning_rate: 0.0001\n",
            "Score: 0.3909774422645569\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "filters_1: 48\n",
            "dropout_1: 0.4\n",
            "filters_2: 128\n",
            "dropout_2: 0.30000000000000004\n",
            "filters_3: 192\n",
            "dropout_3: 0.4\n",
            "dense_units: 128\n",
            "dropout_dense: 0.5\n",
            "learning_rate: 0.0005\n",
            "Score: 0.3909774422645569\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "filters_1: 48\n",
            "dropout_1: 0.4\n",
            "filters_2: 64\n",
            "dropout_2: 0.4\n",
            "filters_3: 128\n",
            "dropout_3: 0.4\n",
            "dense_units: 64\n",
            "dropout_dense: 0.4\n",
            "learning_rate: 0.0005\n",
            "Score: 0.3909774422645569\n"
          ]
        }
      ],
      "source": [
        "# Mostrar resumen de la búsqueda de hiperparámetros\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaitSY2qdag7",
        "outputId": "de503464-d17f-42a8-9323-319d5595f412"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carlos/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor modelo encontrado con filtros: 32, 96, 128, learning rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carlos/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 38 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Obtener el mejor modelo y sus hiperparámetros encontrados\n",
        "# =============================================================================\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "print(\n",
        "    f\"Mejor modelo encontrado con filtros: {best_hps.get('filters_1')}, {best_hps.get('filters_2')}, {best_hps.get('filters_3')}, learning rate: {best_hps.get('learning_rate')}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fQut8wEesIm7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/carlos/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 5s/step - AUC: 0.9981 - accuracy: 0.9914 - loss: 0.0419 - precision: 0.9914 - recall: 0.9914 - val_AUC: 0.6776 - val_accuracy: 0.6241 - val_loss: 1.6306 - val_precision: 0.6241 - val_recall: 0.6241\n",
            "Epoch 2/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 5s/step - AUC: 0.9984 - accuracy: 0.9817 - loss: 0.0501 - precision: 0.9817 - recall: 0.9817 - val_AUC: 0.9757 - val_accuracy: 0.9699 - val_loss: 0.1510 - val_precision: 0.9699 - val_recall: 0.9699\n",
            "Epoch 3/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 5s/step - AUC: 0.9966 - accuracy: 0.9857 - loss: 0.0586 - precision: 0.9857 - recall: 0.9857 - val_AUC: 0.9739 - val_accuracy: 0.9624 - val_loss: 0.1353 - val_precision: 0.9624 - val_recall: 0.9624\n",
            "Epoch 4/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9966 - loss: 0.0216 - precision: 0.9966 - recall: 0.9966 - val_AUC: 0.9750 - val_accuracy: 0.9624 - val_loss: 0.1510 - val_precision: 0.9624 - val_recall: 0.9624\n",
            "Epoch 5/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 5s/step - AUC: 0.9995 - accuracy: 0.9871 - loss: 0.0361 - precision: 0.9871 - recall: 0.9871 - val_AUC: 0.9557 - val_accuracy: 0.9248 - val_loss: 0.2361 - val_precision: 0.9248 - val_recall: 0.9248\n",
            "Epoch 6/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 5s/step - AUC: 0.9995 - accuracy: 0.9935 - loss: 0.0293 - precision: 0.9935 - recall: 0.9935 - val_AUC: 0.6417 - val_accuracy: 0.5865 - val_loss: 1.8349 - val_precision: 0.5865 - val_recall: 0.5865\n",
            "Epoch 7/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 5s/step - AUC: 0.9963 - accuracy: 0.9862 - loss: 0.0453 - precision: 0.9862 - recall: 0.9862 - val_AUC: 0.9819 - val_accuracy: 0.9549 - val_loss: 0.1361 - val_precision: 0.9549 - val_recall: 0.9549\n",
            "Epoch 8/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - AUC: 0.9989 - accuracy: 0.9923 - loss: 0.0344 - precision: 0.9923 - recall: 0.9923 - val_AUC: 0.9813 - val_accuracy: 0.9549 - val_loss: 0.1113 - val_precision: 0.9549 - val_recall: 0.9549\n",
            "Epoch 9/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 5s/step - AUC: 0.9996 - accuracy: 0.9948 - loss: 0.0205 - precision: 0.9948 - recall: 0.9948 - val_AUC: 0.9703 - val_accuracy: 0.9398 - val_loss: 0.1870 - val_precision: 0.9398 - val_recall: 0.9398\n",
            "Epoch 10/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 5s/step - AUC: 0.9994 - accuracy: 0.9908 - loss: 0.0249 - precision: 0.9908 - recall: 0.9908 - val_AUC: 0.9476 - val_accuracy: 0.9173 - val_loss: 0.3173 - val_precision: 0.9173 - val_recall: 0.9173\n",
            "Epoch 11/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 5s/step - AUC: 0.9994 - accuracy: 0.9900 - loss: 0.0296 - precision: 0.9900 - recall: 0.9900 - val_AUC: 0.4116 - val_accuracy: 0.3985 - val_loss: 3.6748 - val_precision: 0.3985 - val_recall: 0.3985\n",
            "Epoch 12/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 5s/step - AUC: 0.9964 - accuracy: 0.9885 - loss: 0.0427 - precision: 0.9885 - recall: 0.9885 - val_AUC: 0.9843 - val_accuracy: 0.9474 - val_loss: 0.1547 - val_precision: 0.9474 - val_recall: 0.9474\n",
            "Epoch 13/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9999 - loss: 0.0106 - precision: 0.9999 - recall: 0.9999 - val_AUC: 0.9908 - val_accuracy: 0.9699 - val_loss: 0.0928 - val_precision: 0.9699 - val_recall: 0.9699\n",
            "Epoch 14/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9987 - loss: 0.0076 - precision: 0.9987 - recall: 0.9987 - val_AUC: 0.9262 - val_accuracy: 0.8947 - val_loss: 0.3661 - val_precision: 0.8947 - val_recall: 0.8947\n",
            "Epoch 15/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9993 - loss: 0.0091 - precision: 0.9993 - recall: 0.9993 - val_AUC: 0.9920 - val_accuracy: 0.9925 - val_loss: 0.0699 - val_precision: 0.9925 - val_recall: 0.9925\n",
            "Epoch 16/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9986 - loss: 0.0076 - precision: 0.9986 - recall: 0.9986 - val_AUC: 0.9245 - val_accuracy: 0.9098 - val_loss: 0.3673 - val_precision: 0.9098 - val_recall: 0.9098\n",
            "Epoch 17/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9970 - loss: 0.0100 - precision: 0.9970 - recall: 0.9970 - val_AUC: 0.9902 - val_accuracy: 0.9774 - val_loss: 0.0960 - val_precision: 0.9774 - val_recall: 0.9774\n",
            "Epoch 18/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9993 - loss: 0.0078 - precision: 0.9993 - recall: 0.9993 - val_AUC: 0.9236 - val_accuracy: 0.8872 - val_loss: 0.4734 - val_precision: 0.8872 - val_recall: 0.8872\n",
            "Epoch 19/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9996 - loss: 0.0055 - precision: 0.9996 - recall: 0.9996 - val_AUC: 0.9825 - val_accuracy: 0.9474 - val_loss: 0.1320 - val_precision: 0.9474 - val_recall: 0.9474\n",
            "Epoch 20/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 5s/step - AUC: 0.9999 - accuracy: 0.9968 - loss: 0.0136 - precision: 0.9968 - recall: 0.9968 - val_AUC: 0.9075 - val_accuracy: 0.8797 - val_loss: 0.5381 - val_precision: 0.8797 - val_recall: 0.8797\n",
            "Epoch 21/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9998 - loss: 0.0076 - precision: 0.9998 - recall: 0.9998 - val_AUC: 0.6814 - val_accuracy: 0.6391 - val_loss: 1.6661 - val_precision: 0.6391 - val_recall: 0.6391\n",
            "Epoch 22/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 5s/step - AUC: 0.9999 - accuracy: 0.9957 - loss: 0.0158 - precision: 0.9957 - recall: 0.9957 - val_AUC: 0.9737 - val_accuracy: 0.9474 - val_loss: 0.2063 - val_precision: 0.9474 - val_recall: 0.9474\n",
            "Epoch 23/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 1.0000 - loss: 0.0047 - precision: 1.0000 - recall: 1.0000 - val_AUC: 0.9760 - val_accuracy: 0.9699 - val_loss: 0.1617 - val_precision: 0.9699 - val_recall: 0.9699\n",
            "Epoch 24/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 1.0000 - loss: 0.0054 - precision: 1.0000 - recall: 1.0000 - val_AUC: 0.9839 - val_accuracy: 0.9699 - val_loss: 0.1130 - val_precision: 0.9699 - val_recall: 0.9699\n",
            "Epoch 25/25\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - AUC: 1.0000 - accuracy: 0.9973 - loss: 0.0065 - precision: 0.9973 - recall: 0.9973 - val_AUC: 0.9647 - val_accuracy: 0.9474 - val_loss: 0.2511 - val_precision: 0.9474 - val_recall: 0.9474\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Entrenar el mejor modelo utilizando el conjunto de entrenamiento y validación.\n",
        "# Se extrae el historial de entrenamiento para su análisis posterior.\n",
        "# =============================================================================\n",
        "history = best_model.fit(train_generator, validation_data=test_generator, epochs=25)\n",
        "\n",
        "# =============================================================================\n",
        "# Convertir el historial de entrenamiento a un DataFrame para analizar las métricas.\n",
        "# =============================================================================\n",
        "df_metrics = pd.DataFrame(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas guardadas en: ./results/csv_files/training_metrics_binary.csv\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Guardar el DataFrame con las métricas de entrenamiento en un archivo CSV,\n",
        "# usando una estructura de carpetas organizada.\n",
        "# =============================================================================\n",
        "csv_dir = \"./results/csv_files\"\n",
        "os.makedirs(csv_dir, exist_ok=True)\n",
        "\n",
        "csv_metrics_path = os.path.join(csv_dir, \"training_metrics_binary.csv\")\n",
        "df_metrics.to_csv(csv_metrics_path, index=False)\n",
        "print(\"Métricas guardadas en:\", csv_metrics_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb5IIvzoY7oM",
        "outputId": "4c5927e5-2c9e-46de-aafb-955511945f5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor binary modelo guardado en: ./results/binary/models/best_binary_model.h5\n",
            "Pesos del binary modelo guardados en: ./results/binary/weights/best_binary.weights.h5\n",
            "Hiperparámetros del binary modelo guardados en: ./results/binary/hyperparameters/best_binary_hyperparameters.json\n"
          ]
        }
      ],
      "source": [
        "def save_model_structure(best_model, best_hps, model_type):\n",
        "    \"\"\"\n",
        "    Guarda el modelo completo, sus pesos y los hiperparámetros en una estructura organizada.\n",
        "\n",
        "    Args:\n",
        "        best_model: Modelo de Keras a guardar.\n",
        "        best_hps: Objeto de hiperparámetros (por ejemplo, de Keras Tuner).\n",
        "        model_type: Cadena identificadora (\"multiclass\" o \"binary\") para crear subcarpetas específicas.\n",
        "    \"\"\"\n",
        "    # Definir la carpeta base para el tipo de modelo (multiclass o binary)\n",
        "    base_dir = f\"./results/{model_type}\"\n",
        "\n",
        "    # Crear subcarpetas para modelos, pesos e hiperparámetros\n",
        "    models_dir = os.path.join(base_dir, \"models\")\n",
        "    weights_dir = os.path.join(base_dir, \"weights\")\n",
        "    hyperparams_dir = os.path.join(base_dir, \"hyperparameters\")\n",
        "\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "    os.makedirs(weights_dir, exist_ok=True)\n",
        "    os.makedirs(hyperparams_dir, exist_ok=True)\n",
        "\n",
        "    # Guardar el modelo completo en la carpeta 'models'\n",
        "    model_path = os.path.join(models_dir, f\"best_{model_type}_model.h5\")\n",
        "    best_model.save(model_path)\n",
        "    print(f\"Mejor {model_type} modelo guardado en:\", model_path)\n",
        "\n",
        "    # Guardar solo los pesos del modelo en la carpeta 'weights'\n",
        "    weights_path = os.path.join(weights_dir, f\"best_{model_type}.weights.h5\")\n",
        "    best_model.save_weights(weights_path)\n",
        "    print(f\"Pesos del {model_type} modelo guardados en:\", weights_path)\n",
        "\n",
        "    # Guardar los hiperparámetros del modelo en formato JSON en la carpeta 'hyperparameters'\n",
        "    hyperparams_path = os.path.join(\n",
        "        hyperparams_dir, f\"best_{model_type}_hyperparameters.json\"\n",
        "    )\n",
        "    with open(hyperparams_path, \"w\") as json_file:\n",
        "        json.dump(best_hps.values, json_file, indent=4)\n",
        "    print(f\"Hiperparámetros del {model_type} modelo guardados en:\", hyperparams_path)\n",
        "\n",
        "\n",
        "# Ejemplo de uso para el modelo binario:\n",
        "save_model_structure(best_model, best_hps, \"binary\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
