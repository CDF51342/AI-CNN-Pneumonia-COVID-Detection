{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ebmAvysVeA"
      },
      "source": [
        "# Importaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPJiBA0FaWlB",
        "outputId": "702f5593-ca2c-4721-c913-f368a8880e8a"
      },
      "outputs": [],
      "source": [
        "# Importar librerías necesarias\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Establecer la semilla para reproducibilidad\n",
        "random.seed(42)\n",
        "\n",
        "# Definir la carpeta para guardar los CSV\n",
        "csv_dir = \"./results/csv_files\"\n",
        "os.makedirs(csv_dir, exist_ok=True)  # Crea la carpeta si no existe\n",
        "\n",
        "# Directorio raíz de las imágenes reales\n",
        "# (Carpeta que contiene subcarpetas \"Bacterial\", \"COVID-19\" y \"Normal\")\n",
        "real_data_dir = \"./data/covid-chest-xray\"\n",
        "\n",
        "# Directorio de las imágenes aumentadas\n",
        "# (Carpeta que contiene subcarpetas \"Bacterial\", \"COVID-19\" y \"Normal\")\n",
        "augmented_data_dir = \"./data/data_augmentation\"\n",
        "\n",
        "# Lista de clases según la estructura de tus carpetas\n",
        "clases = [\"Bacterial\", \"COVID-19\", \"Normal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bacterial: 48 imágenes reales\n",
            "COVID-19: 342 imágenes reales\n",
            "Normal: 486 imágenes reales\n"
          ]
        }
      ],
      "source": [
        "def obtener_rutas_imagenes(ruta_base, extension=(\"jpg\", \"jpeg\", \"png\", \"tiff\")):\n",
        "    rutas = []\n",
        "    for ext in extension:\n",
        "        rutas.extend(glob.glob(os.path.join(ruta_base, f\"*.{ext}\")))\n",
        "    return rutas\n",
        "\n",
        "\n",
        "# Crear un diccionario con las rutas de imágenes reales para cada clase\n",
        "imagenes_reales = {}\n",
        "for clase in clases:\n",
        "    ruta_clase = os.path.join(real_data_dir, clase)\n",
        "    imagenes_reales[clase] = obtener_rutas_imagenes(ruta_clase)\n",
        "    print(f\"{clase}: {len(imagenes_reales[clase])} imágenes reales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bacterial - Total: 48, Train: 33, Val: 7, Test: 8\n",
            "COVID-19 - Total: 342, Train: 239, Val: 51, Test: 52\n",
            "Normal - Total: 486, Train: 340, Val: 72, Test: 74\n"
          ]
        }
      ],
      "source": [
        "# Definir porcentajes\n",
        "porc_train = 0.70\n",
        "porc_val = 0.15\n",
        "porc_test = 0.15\n",
        "\n",
        "# Diccionarios para almacenar las rutas de cada conjunto\n",
        "train_real = {}\n",
        "val_real = {}\n",
        "test_real = {}\n",
        "\n",
        "for clase in clases:\n",
        "    imagenes = imagenes_reales[clase].copy()\n",
        "    random.shuffle(imagenes)\n",
        "\n",
        "    total = len(imagenes)\n",
        "    n_train = int(total * porc_train)\n",
        "    n_val = int(total * porc_val)\n",
        "    # El resto va a test, asegurando que se asignen todas las imágenes\n",
        "    n_test = total - n_train - n_val\n",
        "\n",
        "    train_real[clase] = imagenes[:n_train]\n",
        "    val_real[clase] = imagenes[n_train : n_train + n_val]\n",
        "    test_real[clase] = imagenes[n_train + n_val :]\n",
        "\n",
        "    print(\n",
        "        f\"{clase} - Total: {total}, Train: {len(train_real[clase])}, Val: {len(val_real[clase])}, Test: {len(test_real[clase])}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Conjunto      Clase                                               Ruta\n",
            "0    train  Bacterial  ./data/covid-chest-xray/Bacterial/Bacterial-2.jpg\n",
            "1    train  Bacterial  ./data/covid-chest-xray/Bacterial/Bacterial-38...\n",
            "2    train  Bacterial  ./data/covid-chest-xray/Bacterial/Bacterial-1.jpg\n",
            "3    train  Bacterial  ./data/covid-chest-xray/Bacterial/Bacterial-35...\n",
            "4    train  Bacterial  ./data/covid-chest-xray/Bacterial/Bacterial-11...\n",
            "Conjunto  Clase    \n",
            "test      Bacterial      8\n",
            "          COVID-19      52\n",
            "          Normal        74\n",
            "train     Bacterial     33\n",
            "          COVID-19     239\n",
            "          Normal       340\n",
            "val       Bacterial      7\n",
            "          COVID-19      51\n",
            "          Normal        72\n",
            "dtype: int64\n",
            "Registro de imágenes guardado en: ./results/csv_files/registro_imagenes_reales.csv\n"
          ]
        }
      ],
      "source": [
        "def crear_registro(rutas_dict, conjunto_name):\n",
        "    registros = []\n",
        "    for clase, rutas in rutas_dict.items():\n",
        "        for ruta in rutas:\n",
        "            registros.append({\"Conjunto\": conjunto_name, \"Clase\": clase, \"Ruta\": ruta})\n",
        "    return pd.DataFrame(registros)\n",
        "\n",
        "\n",
        "df_train = crear_registro(train_real, \"train\")\n",
        "df_val = crear_registro(val_real, \"val\")\n",
        "df_test = crear_registro(test_real, \"test\")\n",
        "\n",
        "# Concatenar y mostrar el registro completo\n",
        "df_registro = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
        "print(df_registro.head())\n",
        "print(df_registro.groupby([\"Conjunto\", \"Clase\"]).size())\n",
        "\n",
        "# Guardar el registro de imágenes reales\n",
        "csv_registro_imagenes = os.path.join(csv_dir, \"registro_imagenes_reales.csv\")\n",
        "df_registro.to_csv(csv_registro_imagenes, index=False)\n",
        "print(f\"Registro de imágenes guardado en: {csv_registro_imagenes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bacterial: 1000 imágenes aumentadas\n",
            "COVID-19: 1000 imágenes aumentadas\n",
            "Normal: 1000 imágenes aumentadas\n"
          ]
        }
      ],
      "source": [
        "# Diccionario para almacenar rutas de imágenes aumentadas por clase\n",
        "imagenes_aug = {}\n",
        "for clase in clases:\n",
        "    ruta_clase_aug = os.path.join(augmented_data_dir, clase)\n",
        "    imagenes_aug[clase] = obtener_rutas_imagenes(ruta_clase_aug)\n",
        "    print(f\"{clase}: {len(imagenes_aug[clase])} imágenes aumentadas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bacterial - Train final: 33 reales + 1000 aumentadas = 1033 imágenes\n",
            "COVID-19 - Train final: 239 reales + 1000 aumentadas = 1239 imágenes\n",
            "Normal - Train final: 340 reales + 1000 aumentadas = 1340 imágenes\n"
          ]
        }
      ],
      "source": [
        "# Diccionario para el conjunto de entrenamiento final (reales + aumentadas)\n",
        "train_final = {}\n",
        "\n",
        "for clase in clases:\n",
        "    reales = train_real[clase]\n",
        "    aumentadas = imagenes_aug.get(clase, [])\n",
        "    train_final[clase] = reales + aumentadas\n",
        "    print(\n",
        "        f\"{clase} - Train final: {len(reales)} reales + {len(aumentadas)} aumentadas = {len(train_final[clase])} imágenes\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clase\n",
            "Bacterial    1033\n",
            "COVID-19     1239\n",
            "Normal       1340\n",
            "dtype: int64\n",
            "Registro del conjunto de entrenamiento final guardado en: ./results/csv_files/registro_train_final.csv\n"
          ]
        }
      ],
      "source": [
        "df_train_final = crear_registro(train_final, \"train_final\")\n",
        "\n",
        "# Mostrar resumen por clase\n",
        "print(df_train_final.groupby(\"Clase\").size())\n",
        "\n",
        "# Guardar el registro del conjunto de entrenamiento final (reales + aumentadas)\n",
        "csv_train_final = os.path.join(csv_dir, \"registro_train_final.csv\")\n",
        "df_train_final.to_csv(csv_train_final, index=False)\n",
        "print(f\"Registro del conjunto de entrenamiento final guardado en: {csv_train_final}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "División de imágenes reales:\n",
            "         Conjunto  Bacterial  COVID-19  Normal\n",
            "0  Train (reales)         33       239     340\n",
            "1             Val          7        51      72\n",
            "2            Test          8        52      74\n",
            "\n",
            "Conjunto de entrenamiento final (reales + aumentadas):\n",
            "       Clase  Train_final\n",
            "0  Bacterial         1033\n",
            "1   COVID-19         1239\n",
            "2     Normal         1340\n"
          ]
        }
      ],
      "source": [
        "# Resumen de las cantidades en cada conjunto\n",
        "resumen = {\n",
        "    \"Conjunto\": [\"Train (reales)\", \"Val\", \"Test\"],\n",
        "    \"Bacterial\": [\n",
        "        len(train_real[\"Bacterial\"]),\n",
        "        len(val_real[\"Bacterial\"]),\n",
        "        len(test_real[\"Bacterial\"]),\n",
        "    ],\n",
        "    \"COVID-19\": [\n",
        "        len(train_real[\"COVID-19\"]),\n",
        "        len(val_real[\"COVID-19\"]),\n",
        "        len(test_real[\"COVID-19\"]),\n",
        "    ],\n",
        "    \"Normal\": [\n",
        "        len(train_real[\"Normal\"]),\n",
        "        len(val_real[\"Normal\"]),\n",
        "        len(test_real[\"Normal\"]),\n",
        "    ],\n",
        "}\n",
        "\n",
        "df_resumen = pd.DataFrame(resumen)\n",
        "print(\"División de imágenes reales:\")\n",
        "print(df_resumen)\n",
        "\n",
        "# Resumen de imágenes en el entrenamiento final (reales + aumentadas)\n",
        "resumen_train_final = {\n",
        "    \"Clase\": clases,  # [\"Bacterial\", \"COVID-19\", \"Normal\"]\n",
        "    \"Train_final\": [len(train_final[clase]) for clase in clases],\n",
        "}\n",
        "\n",
        "df_resumen_train_final = pd.DataFrame(resumen_train_final)\n",
        "print(\"\\nConjunto de entrenamiento final (reales + aumentadas):\")\n",
        "print(df_resumen_train_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3612 validated image filenames belonging to 3 classes.\n",
            "Clases encontradas: {'Bacterial': 0, 'COVID-19': 1, 'Normal': 2}\n",
            "Found 134 validated image filenames belonging to 3 classes.\n",
            "Clases encontradas en test: {'Bacterial': 0, 'COVID-19': 1, 'Normal': 2}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Crear generador para el conjunto de entrenamiento (solo rescaling)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Crear el generador de datos a partir del DataFrame de entrenamiento (imágenes reales + aumentadas)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=df_train_final,  # DataFrame con las imágenes de entrenamiento\n",
        "    x_col=\"Ruta\",  # Columna con las rutas de las imágenes\n",
        "    y_col=\"Clase\",  # Columna con las etiquetas de clase\n",
        "    target_size=(224, 224),  # Redimensionar las imágenes a 224x224\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",  # Para clasificación multiclase\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(\"Clases encontradas:\", train_generator.class_indices)\n",
        "\n",
        "# Crear generador para test (solo rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Filtrar el DataFrame para obtener solo las imágenes del conjunto \"test\"\n",
        "df_test = df_registro[df_registro[\"Conjunto\"] == \"test\"]\n",
        "\n",
        "# Crear el generador de datos para el conjunto de test\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=df_test,  # DataFrame con las imágenes reales de test\n",
        "    x_col=\"Ruta\",  # Columna que contiene las rutas de las imágenes\n",
        "    y_col=\"Clase\",  # Columna con las etiquetas de clase\n",
        "    target_size=(224, 224),  # Redimensiona las imágenes a 224x224\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",  # Para clasificación multiclase\n",
        "    shuffle=False,  # No se baraja para mantener el orden de test\n",
        ")\n",
        "\n",
        "print(\"Clases encontradas en test:\", test_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc3EsCw8YUVZ",
        "outputId": "62fbb4bf-e399-42a1-db55-a5bfaeebc92b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'kerastuner'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkerastuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomSearch\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m  \u001b[38;5;66;03m# Importar librerías necesarias\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'"
          ]
        }
      ],
      "source": [
        "# Importar librerías necesarias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    BatchNormalization,\n",
        "    Activation,\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IbHdRdMYWk9"
      },
      "source": [
        "# Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Definir la función que construye el modelo de CNN, con hiperparámetros ajustables.\n",
        "# =============================================================================\n",
        "def build_cnn(hp):\n",
        "    model = Sequential(\n",
        "        [\n",
        "            # Primera capa convolucional: se parametriza el número de filtros (entre 32 y 64, de 16 en 16)\n",
        "            Conv2D(\n",
        "                hp.Int(\"filters_1\", 32, 64, step=16),\n",
        "                (3, 3),\n",
        "                activation=None,\n",
        "                input_shape=(224, 224, 3),\n",
        "            ),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(hp.Float(\"dropout_1\", 0.2, 0.5, step=0.1)),\n",
        "            \n",
        "            # Segunda capa convolucional\n",
        "            Conv2D(hp.Int(\"filters_2\", 64, 128, step=32), (3, 3), activation=None),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(hp.Float(\"dropout_2\", 0.2, 0.5, step=0.1)),\n",
        "            \n",
        "            # Tercera capa convolucional\n",
        "            Conv2D(hp.Int(\"filters_3\", 128, 256, step=64), (3, 3), activation=None),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Dropout(hp.Float(\"dropout_3\", 0.3, 0.6, step=0.1)),\n",
        "            \n",
        "            # Capa de aplanamiento para pasar a las capas densas\n",
        "            Flatten(),\n",
        "            \n",
        "            # Capa densa con unidades parametrizables (entre 64 y 256, de 64 en 64)\n",
        "            Dense(hp.Int(\"dense_units\", 64, 256, step=64), activation=None),\n",
        "            BatchNormalization(),\n",
        "            Activation(\"relu\"),\n",
        "            Dropout(hp.Float(\"dropout_dense\", 0.3, 0.6, step=0.1)),\n",
        "            \n",
        "            # Capa de salida: 3 neuronas para 3 clases, con activación softmax\n",
        "            Dense(3, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Definir el optimizador: Adam con tasa de aprendizaje seleccionada entre tres opciones.\n",
        "    optimizer = Adam(learning_rate=hp.Choice(\"learning_rate\", [1e-4, 5e-4, 1e-3]))\n",
        "\n",
        "    # Compilar el modelo usando entropía cruzada categórica (para clasificación multiclase)\n",
        "    # Se añaden varias métricas para evaluar: accuracy, precision, recall y AUC.\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=optimizer,\n",
        "        metrics=[\"accuracy\", \"precision\", \"recall\", \"AUC\"],\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yj45LgkYb72"
      },
      "source": [
        "# Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY3NrE6fYpyA"
      },
      "source": [
        "# Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Configurar el Random Search para buscar los mejores hiperparámetros\n",
        "# =============================================================================\n",
        "tuner = RandomSearch(\n",
        "    build_cnn,  # Función que construye el modelo\n",
        "    objective=\"val_accuracy\",  # Métrica a optimizar (precisión en validación)\n",
        "    max_trials=50,  # Número máximo de combinaciones a probar\n",
        "    executions_per_trial=1,  # Número de ejecuciones por cada combinación\n",
        "    directory=\"cnn_chest-xray_problem2\",  # Directorio para guardar resultados del tuner\n",
        "    project_name=\"cnn_chest-xray_problem2\",  # Nombre del proyecto\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# Definir Early Stopping para detener el entrenamiento si no mejora la precisión de validación\n",
        "# =============================================================================\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# Realizar la búsqueda de hiperparámetros usando los generadores de entrenamiento y validación.\n",
        "# Se asume que 'train_generator' y 'test_generator' están definidos previamente.\n",
        "# =============================================================================\n",
        "tuner.search(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,  # Aquí test_generator actúa como conjunto de validación\n",
        "    epochs=25,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar resumen de la búsqueda de hiperparámetros\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaitSY2qdag7",
        "outputId": "de503464-d17f-42a8-9323-319d5595f412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor modelo encontrado con filtros: 48, 96, 256, learning rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Obtener el mejor modelo y sus hiperparámetros encontrados\n",
        "# =============================================================================\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "print(\n",
        "    f\"Mejor modelo encontrado con filtros: {best_hps.get('filters_1')}, {best_hps.get('filters_2')}, {best_hps.get('filters_3')}, learning rate: {best_hps.get('learning_rate')}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQut8wEesIm7"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Entrenar el mejor modelo utilizando el conjunto de entrenamiento y validación.\n",
        "# Se extrae el historial de entrenamiento para su análisis posterior.\n",
        "# =============================================================================\n",
        "history = best_model.fit(train_generator, validation_data=test_generator, epochs=25)\n",
        "\n",
        "# =============================================================================\n",
        "# Convertir el historial de entrenamiento a un DataFrame para analizar las métricas.\n",
        "# =============================================================================\n",
        "df_metrics = pd.DataFrame(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Guardar el DataFrame con las métricas de entrenamiento en un archivo CSV,\n",
        "# usando una estructura de carpetas organizada.\n",
        "# =============================================================================\n",
        "csv_dir = \"./results/csv_files\"\n",
        "os.makedirs(csv_dir, exist_ok=True)\n",
        "\n",
        "csv_metrics_path = os.path.join(csv_dir, \"training_metrics.csv\")\n",
        "df_metrics.to_csv(csv_metrics_path, index=False)\n",
        "print(\"Métricas guardadas en:\", csv_metrics_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb5IIvzoY7oM",
        "outputId": "4c5927e5-2c9e-46de-aafb-955511945f5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor modelo guardado como 'best_cnn_model.h5'\n"
          ]
        }
      ],
      "source": [
        "def save_model_structure(best_model, best_hps, model_type):\n",
        "    \"\"\"\n",
        "    Guarda el modelo completo, sus pesos y los hiperparámetros en una estructura organizada.\n",
        "\n",
        "    Args:\n",
        "        best_model: Modelo de Keras a guardar.\n",
        "        best_hps: Objeto de hiperparámetros (por ejemplo, de Keras Tuner).\n",
        "        model_type: Cadena identificadora (\"multiclass\" o \"binary\") para crear subcarpetas específicas.\n",
        "    \"\"\"\n",
        "    # Definir la carpeta base para el tipo de modelo (multiclass o binary)\n",
        "    base_dir = f\"./results/{model_type}\"\n",
        "\n",
        "    # Crear subcarpetas para modelos, pesos e hiperparámetros\n",
        "    models_dir = os.path.join(base_dir, \"models\")\n",
        "    weights_dir = os.path.join(base_dir, \"weights\")\n",
        "    hyperparams_dir = os.path.join(base_dir, \"hyperparameters\")\n",
        "\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "    os.makedirs(weights_dir, exist_ok=True)\n",
        "    os.makedirs(hyperparams_dir, exist_ok=True)\n",
        "\n",
        "    # Guardar el modelo completo en la carpeta 'models'\n",
        "    model_path = os.path.join(models_dir, f\"best_{model_type}_model.h5\")\n",
        "    best_model.save(model_path)\n",
        "    print(f\"Mejor {model_type} modelo guardado en:\", model_path)\n",
        "\n",
        "    # Guardar solo los pesos del modelo en la carpeta 'weights'\n",
        "    weights_path = os.path.join(weights_dir, f\"best_{model_type}_weights.h5\")\n",
        "    best_model.save_weights(weights_path)\n",
        "    print(f\"Pesos del {model_type} modelo guardados en:\", weights_path)\n",
        "\n",
        "    # Guardar los hiperparámetros del modelo en formato JSON en la carpeta 'hyperparameters'\n",
        "    hyperparams_path = os.path.join(\n",
        "        hyperparams_dir, f\"best_{model_type}_hyperparameters.json\"\n",
        "    )\n",
        "    with open(hyperparams_path, \"w\") as json_file:\n",
        "        json.dump(best_hps.values, json_file, indent=4)\n",
        "    print(f\"Hiperparámetros del {model_type} modelo guardados en:\", hyperparams_path)\n",
        "\n",
        "\n",
        "# Ejemplo de uso para el modelo multiclase:\n",
        "save_model_structure(best_model, best_hps, \"multiclass\")\n",
        "\n",
        "# Más adelante, cuando entrenes y obtengas el mejor modelo binario,\n",
        "# podrás llamarlo de manera similar:\n",
        "# save_model_structure(best_model_binary, best_hps_binary, \"binary\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
